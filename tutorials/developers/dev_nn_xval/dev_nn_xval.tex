\documentclass{tufte-handout}
\usepackage{../braph2_dev}
%\geometry{showframe} % display margins for debugging page layout

\title{Implement Cross Validation for Neural Network}

\author[The BRAPH~2 Developers]{The BRAPH~2 Developers}

\begin{document}

\maketitle

\begin{abstract}
\noindent
This is the developer tutorial for implementing a new neural network cross validation. 
In this tutorial, you will learn how to create the generator file \fn{*.gen.m} for a new neural network cross validation, which can then be compiled by \code{braph2genesis}. All kinds of neural network cross validation are (direct or indirect) extensions of the base element \code{NNCrossValidation}. Here, you will use as examples \code{NNRegressorMLP\_CrossValidation} (a cross validation for multi-layer perceptron regressors) and \code{NNClassifierMLP\_CrossValidation} (a cross validation for multi-layer perceptron classifiers).
\end{abstract}

\tableofcontents

\clearpage

\section{Cross validation for regressors (\code{NNRegressorMLP\_CrossValidation})}

You will start by implementing in detail \code{NNRegressorMLP\_CrossValidation}, which is a direct extension of \code{NNCrossValidation}.
\code{NNRegressorMLP\_CrossValidation} performs a procedure designed for evaluating multi-layer perceptron regressors using cross-validation. 

\begin{lstlisting}[
	label=cd:m:NNRegressorMLP_CrossValidation:header,
	caption={
		{\bf NNRegressorMLP\_CrossValidation element header.}
		The \code{header} section of the generator code for \fn{\_NNRegressorMLP\_CrossValidation.gen.m} provides the general information about the \code{NNRegressorMLP\_CrossValidation} element.
		}
]
%% ¡header!
NNRegressorMLP_CrossValidation < NNCrossValidation (nncv, neural network cross-validation) is a process for evaluating multi-layer perceptron regressors using cross-validation. ¥\circled{1}\circlednote{1}{ defines \code{NNRegressorMLP\_CrossValidation.gen} as a subclass of \code{NNCrossValidation}. The moniker will be \code{nncv}.}¥

%%% ¡description!
A cross validation for multi-layer perceptron regressors (NNRegressorMLP_CrossValidation) is a process that facilitates the evaluation of multi-layer perceptron regressors using cross-validation. 
 It involves splitting a dataset into multiple subsets (folds), training the model on some folds while validating on others, and then repeating the process for all combinations of folds. 
 This helps in assessing the generalization performance of the model and detecting overfitting.

To train all the neural networks for all folds, use: nncv.get('TRAIN')

%%% ¡build!
1
\end{lstlisting}

\begin{lstlisting}[
	label={cd:m:NNRegressorMLP_CrossValidation:prop_update},
	caption={
		{\bf NNRegressorMLP\_CrossValidation element prop update.}
		The \code{props\_update} section of the generator code for \fn{\_NNRegressorMLP\_CrossValidation.gen.m} updates the properties of the \code{NNRegressorMLP\_CrossValidation} element. This defines the core properties of the cross validation.
	}
]
%% ¡props_update!

%%% ¡prop!
NAME (constant, string) is the name of the cross-validation.
%%%% ¡default!
'NNRegressorMLP_CrossValidation'

%%% ¡prop!
DESCRIPTION (constant, string) is the description of the cross-validation.
%%%% ¡default!
'A cross validation for multi-layer perceptron regressors (NNRegressorMLP_CrossValidation) is a process that facilitates the evaluation of multi-layer perceptron regressors using cross-validation. It involves splitting a dataset into multiple subsets (folds), training the model on some folds while validating on others, and then repeating the process for all combinations of folds. This helps in assessing the generalization performance of the model and detecting overfitting.'

%%% ¡prop!
TEMPLATE (parameter, item) is the template of the nerual cross-validation.
%%%% ¡settings!
'NNRegressorMLP_CrossValidation'

%%% ¡prop!
ID (data, string) is a few-letter code for the cross-validation.
%%%% ¡default!
'NNRegressorMLP_CrossValidation ID'

%%% ¡prop!
LABEL (metadata, string) is an extended label of the cross-validation.
%%%% ¡default!
'NNRegressorMLP_CrossValidation label'

%%% ¡prop!
NOTES (metadata, string) are some specific notes about the cross-validation.
%%%% ¡default!
'NNRegressorMLP_CrossValidation notes'

%%% ¡prop!
NN_TEMPLATE (parameter, item) is the neural network template to set all neural network parameters.
%%%% ¡settings!
'NNRegressorMLP' ¥\circled{1}\circlednote{1}{ defines the neural network template to be \code{NNRegressorMLP}, which will be used to set the parameters for all the neural network regressors for the cross validation.}¥

%%% ¡prop!
NNEVALUATOR_TEMPLATE (parameter, item) is the neural network evaluator template to set all evalutor parameters.
%%%% ¡settings!
'NNRegressorMLP_Evaluator' ¥\circled{2}\circlednote{2}{ defines the neural network evaluator template to be \code{NNRegressorMLP\_Evaluator}, which will be used to set the parameters for all the neural network evaluators for the cross validation.}¥ ¥\circled{0}\circlednote{0}{{\bf should this be explained either here or in another tutorial?}}¥

%%% ¡prop!
NN_LIST (result, itemlist) contains the neural network models corresponding to k folds.
%%%% ¡calculate!
d_list = nncv.get('D_LIST');

if isempty(d_list)
    value = {};
else
    for i = 1:length(d_list) ¥\circled{3}\circlednote{3}{ constructs the training sets iteratively by concatenating all of the remaining folds after exlcuding the one as the validation set.}¥
        d_training_set{i} = d_list;
        d_training_set{i}(i) = [];  % Exclude the i-th element
        d_training_set{i} = NNDatasetCombine('D_LIST', d_training_set{i}).get('D');
    end

    d_training_set = d_training_set';

    if ~isa(nncv.getr('NN_TEMPLATE'), 'NoValue')
        nn_template = nncv.get('NN_TEMPLATE'); ¥\circled{4}\circlednote{4}{ and \circled{5} set the parameters to all the \code{NNRegressorMLP}s based on either the \code{NN\_TEMPLATE} or the parameters from this cross validation.}¥
    else
        nn_template = NNRegressorMLP( ... ¥\circled{5}¥
            'EPOCHS', nncv.get('EPOCHS'), ...
            'BATCH', nncv.get('BATCH'), ...
            'SHUFFLE', nncv.get('SHUFFLE'), ...
            'SOLVER', nncv.get('SOLVER'), ...
            'VERBOSE', nncv.get('VERBOSE'), ...
            'PLOT_TRAINING', nncv.get('PLOT_TRAINING'));
    end
    
    value = cellfun(@(d) NNRegressorMLP( ... ¥\circled{6}\circlednote{6}{ initializes all of the \code{NNRegressorMLP}s.}¥
        'TEMPLATE', nn_template, 'D', d), ...
        d_training_set, 'UniformOutput', false);
end

%%% ¡prop!
EVALUATOR_LIST (result, itemlist) contains the evaluators corresponding to k folds.
%%%% ¡calculate!
%%% ¡prop!
EVALUATOR_LIST (result, itemlist) contains the evaluators corresponding to k folds.
%%%% ¡calculate!
d_list = nncv.get('D_LIST');
nn_list = nncv.get('NN_LIST');

if ~isa(nncv.getr('NNEVALUATOR_TEMPLATE'), 'NoValue')
    nne_template = nncv.get('NNEVALUATOR_TEMPLATE'); ¥\circled{7}\circlednote{7}{ and \circled{8} sets the parameters to all the \code{NNRegressorMLP\_Evaluator}s based on either the \code{NNEVALUATOR\_TEMPLATE} or the parameters from this cross validation.}¥
else
    nne_template = NNRegressorMLP_Evaluator( ...  ¥\circled{8}¥
        'P', nncv.get('P'));
end

value = cellfun(@(d, nn) NNRegressorMLP_Evaluator('TEMPLATE', nne_template, 'D', d, 'NN', nn), ... ¥\circled{9}\circlednote{9}{ initializes all of the \code{NNRegressorMLP\_Evaluator}s.}¥
    d_list, nn_list, 'UniformOutput', false);

\end{lstlisting}

\begin{lstlisting}[
	label={cd:m:NNRegressorMLP_CrossValidation:props},
	caption={
		{\bf NNRegressorMLP\_CrossValidation element props.}
		The \code{props} section of generator code for \fn{\_NNRegressorMLP\_CrossValidation.gen.m} defines the properties to be used in \fn{NNRegressorMLP\_CrossValidation}.
	}
]
%% ¡props!

%%% ¡prop!
P (parameter, scalar) is the permutation number.¥\circled{1}\circlednote{1}{ defines the number for permuation feature importance.}¥
%%%% ¡default!
1e+2
%%%% ¡check_prop!
check = value > 0 && value == round(value);

%%% ¡prop!
AV_CORR (result, rvector) provides the metric of the correlation of coefficients. ¥\circled{2}\circlednote{2}{---\circled{5} calculate the average metrics, including the correlation of coefficients, the coefficient of determination, the mean absolute error, the mean squared error, and the root mean squared error.}¥
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

value = cellfun(@(e) e.get('CORR'), ...
    e_list, 'UniformOutput', false);

if isempty(value)
    value = [];
else
    value = mean(cell2mat(value), 1);
end

%%% ¡prop!
AV_DET (result, rvector) provides the coefficient of determination, a measure showing how well the predictions are replicated by the model. ¥\circled{3}¥
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

value = cellfun(@(e) e.get('DET'), ...
    e_list, 'UniformOutput', false);

if isempty(value)
    value = [];
else
    value = mean(cell2mat(value), 1);
end

%%% ¡prop!
AV_MAE (result, rvector) provides the metric of the mean absolute error. ¥\circled{4}¥
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

value = cellfun(@(e) e.get('MAE'), ...
    e_list, 'UniformOutput', false);

if isempty(value)
    value = [];
else
    value = mean(cell2mat(value), 1);
end

%%% ¡prop!
AV_MSE (result, rvector) provides the metric of the mean squared error. ¥\circled{5}¥
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

value = cellfun(@(e) e.get('MSE'), ...
    e_list, 'UniformOutput', false);

if isempty(value)
    value = [];
else
    value = mean(cell2mat(value), 1);
end

%%% ¡prop!
AV_RMSE (result, rvector) provides the metric of the root mean squared error. 
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

value = cellfun(@(e) e.get('RMSE'), ...
    e_list, 'UniformOutput', false);

if isempty(value)
    value = [];
else
    value = mean(cell2mat(value), 1);
end

%%% ¡prop!
AV_FEATURE_IMPORTANCE (result, cell) averages the feature importances across k folds. ¥\circled{6}\circlednote{6}{ calculates the average feature importance. The feature importance obtained from each fold is by performing permutation feature importance. For a detailed explanation, please refer to \fn{dev\_nn\_reg.pdf}}¥
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

all_fi = cellfun(@(e) cell2mat(e.get('FEATURE_IMPORTANCE')), ...
    e_list, 'UniformOutput', false);

if isempty(cell2mat(all_fi))
    value = {};
else
    average_fi = zeros(size(all_fi{1}));
    for i = 1:numel(all_fi)
        % Add the current cell contents to the averageCell
        average_fi = average_fi + all_fi{i};
    end
    average_fi = average_fi / numel(all_fi);
    value = {average_fi};
end
\end{lstlisting}

\begin{lstlisting}[
	label=cd:m:NNRegressorMLP_CrossValidation:tests,
	caption={
		{\bf NNRegressorMLP\_CrossValidation element tests.}
		The \code{tests} section from the element generator \fn{\_NNRegressorMLP\_CrossValidation.gen.m}.
		A test for creating example files should be prepared to test the properties of the data point. Furthermore, additional test should be prepared for validating the value of input and target for the data point.
	}
]			
%% ¡tests!

%%% ¡test!
%%%% ¡name!
evaluate a regressor cross-validation with the example data
%%%% ¡code!
% ensure the example data is generated
if ~isfile([fileparts(which('NNDataPoint_CON_REG')) filesep 'Example data NN REG CON XLS' filesep 'atlas.xlsx'])
    test_NNDataPoint_CON_REG % create example files
end

% Load BrainAtlas
im_ba = ImporterBrainAtlasXLS( ...
    'FILE', [fileparts(which('NNDataPoint_CON_REG')) filesep 'Example data NN REG CON XLS' filesep 'atlas.xlsx'], ...
    'WAITBAR', true ...
    );

ba = im_ba.get('BA');

% Load Groups of SubjectCON
im_gr = ImporterGroupSubjectCON_XLS( ...
    'DIRECTORY', [fileparts(which('NNDataPoint_CON_REG')) filesep 'Example data NN REG CON XLS' filesep 'CON_Group_XLS'], ...
    'BA', ba, ...
    'WAITBAR', true ...
    );

gr = im_gr.get('GR');

% create a item list of NNDataPoint_CON_REG
it_list = cellfun(@(x) NNDataPoint_CON_REG( ...
    'ID', x.get('ID'), ...
    'SUB', x, ...
    'TARGET_IDS', x.get('VOI_DICT').get('KEYS')), ...
    gr.get('SUB_DICT').get('IT_LIST'), ...
    'UniformOutput', false);

% create a NNDataPoint_CON_REG DICT
dp_list = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_CON_REG', ...
        'IT_LIST', it_list ...
        );

% create a NNData containing the NNDataPoint_CON_REG DICT
d = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_CON_REG', ...
    'DP_DICT', dp_list ...
    );

kfolds = 3;
nncv = NNRegressorMLP_CrossValidation('KFOLDS', kfolds, 'D', d);

nn_list = nncv.get('NN_LIST');
assert(length(nn_list) == kfolds, ... ¥\circled{1}\circlednote{1}{ and \circled{2} check whether the data, regressors, and evaluators are initialized according to the user-specified number of folds.}¥
    [BRAPH2.STR ':NNRegressorMLP_CrossValidation:' BRAPH2.FAIL_TEST], ...
    'NNRegressorMLP_CrossValidation does not calculate the neural network list correctly.' ...
    )
e_list = nncv.get('EVALUATOR_LIST');
assert(length(e_list) == kfolds, ... ¥\circled{2}¥
    [BRAPH2.STR ':NNRegressorMLP_CrossValidation:' BRAPH2.FAIL_TEST], ...
    'NNRegressorMLP_CrossValidation does not calculate the evaluator list correctly.' ...
    )

\end{lstlisting}

\clearpage

\section{Cross validation for classifiers (\code{NNRegressorMLP\_CrossValidation})}

We can now use \code{NNRegressorMLP\_CrossValidation} as the basis to implement the\code{NNClassifierMLP\_CrossValidation}. The parts of the code that are modified are highlighted.
A cross validation for multi-layer perceptron classifier (\code{NNClassifierMLP\_CrossValidation}) is a procedure designed for evaluating multi-layer perceptron classifiers using cross-validation. 

\begin{lstlisting}[
	label=cd:m:NNClassifierMLP_CrossValidation:header,
	caption={
		{\bf NNClassifierMLP\_CrossValidation element header.}
		The \code{header} section of the generator code for \fn{\_NNClassifierMLP\_CrossValidation.gen.m} provides the general information about the \code{NNClassifierMLP\_CrossValidation} element.
		}
]
¤%% ¡header!¤
NNClassifierMLP_CrossValidation ¤< NNCrossValidation¤ (nncv, neural network cross-validation)¤ is a process for evaluating multi-layer perceptron¤ classifiers ¤using cross-validation.¤

¤%%% ¡description!¤
¤A cross validation for multi-layer perceptron ¤classifiers (NNClassifierMLP_CrossValidation)¤ is a process that facilitates the evaluation of multi-layer perceptron ¤classifiers¤ using cross-validation. 
 It involves splitting a dataset into multiple subsets (folds), training the model on some folds while validating on others, and then repeating the process for all combinations of folds. 
 This helps in assessing the generalization performance of the model and detecting overfitting.

To train all the neural networks for all folds, use: nncv.get('TRAIN')

%%% ¡build!
¤1
\end{lstlisting}

\begin{lstlisting}[
	label={cd:m:NNClassifierMLP_CrossValidation:prop_update},
	caption={
		{\bf NNClassifierMLP\_CrossValidation element prop update.}
		The \code{props\_update} section of the generator code for \fn{\_NNClassifierMLP\_CrossValidation.gen.m} updates the properties of the \code{NNClassifierMLP\_CrossValidation} element. This defines the core properties of the cross validation.
	}
]
¤%% ¡props_update!¤

¤%%% ¡prop!
NAME (constant, string) is the name of the cross-validation.
%%%% ¡default!¤
'NNClassifierMLP_CrossValidation'

¤%%% ¡prop!
DESCRIPTION (constant, string) is the description of the cross-validation.
%%%% ¡default!¤
'A cross validation for multi-layer perceptron classifiers (NNClassifierMLP_CrossValidation) is a process that facilitates the evaluation of multi-layer perceptron classifiers using cross-validation. It involves splitting a dataset into multiple subsets (folds), training the model on some folds while validating on others, and then repeating the process for all combinations of folds. This helps in assessing the generalization performance of the model and detecting overfitting.'

¤%%% ¡prop!
TEMPLATE (parameter, item) is the template of the cross-validation.
%%%% ¡settings!¤
'NNClassifierMLP_CrossValidation'

¤%%% ¡prop!
ID (data, string) is a few-letter code for the cross-validation.
%%%% ¡default!¤
'NNClassifierMLP_CrossValidation ID'

¤%%% ¡prop!
LABEL (metadata, string) is an extended label of the cross-validation.
%%%% ¡default!¤
'NNClassifierMLP_CrossValidation label'

¤%%% ¡prop!
NOTES (metadata, string) are some specific notes about the cross-validation.
%%%% ¡default!¤
'NNClassifierMLP_CrossValidation notes'

¤%%% ¡prop!
NN_TEMPLATE (parameter, item) is the neural network template to set all neural network parameters.
%%%% ¡settings!¤
'NNClassifierMLP'¥\circled{1}\circlednote{1}{ and \circled{2} define the \code{NN\_TEMPLATE} as \code{NNClassifierMLP} and the \code{NNEVALUATOR\_TEMPLATE} as \code{NNClassifierMLP\_Evaluator}.}¥

¤%%% ¡prop!
NNEVALUATOR_TEMPLATE (parameter, item) is the neural network evaluator template to set all evalutor parameters.
%%%% ¡settings!¤
'NNClassifierMLP_Evaluator'¥\circled{2}¥

¤%%% ¡prop!
NN_LIST (result, itemlist) contains the neural network models corresponding to k folds.
%%%% ¡calculate!
d_list = nncv.get('D_LIST');

if isempty(d_list)
    value = {};
else
    for i = 1:length(d_list)
        d_training_set{i} = d_list;
        d_training_set{i}(i) = [];  % Exclude the i-th element
        d_training_set{i} = NNDatasetCombine('D_LIST', d_training_set{i}).get('D');
    end
    
    d_training_set = d_training_set';
    
    if ~isa(nncv.getr('NN_TEMPLATE'), 'NoValue')
        nn_template = nncv.get('NN_TEMPLATE');
    else¤
        nn_template = NNClassifierMLP( ...
            'EPOCHS', nncv.get('EPOCHS'), ...
            'BATCH', nncv.get('BATCH'), ...
            'SHUFFLE', nncv.get('SHUFFLE'), ...
            'SOLVER', nncv.get('SOLVER'), ...
            'VERBOSE', nncv.get('VERBOSE'), ...
            'PLOT_TRAINING', nncv.get('PLOT_TRAINING'));
    end
    
    value = cellfun(@(d) NNClassifierMLP( ...
        'TEMPLATE', nn_template, 'D', d), ...
        d_training_set, 'UniformOutput', false);
¤end¤

¤%%% ¡prop!
EVALUATOR_LIST (result, itemlist) contains the evaluators corresponding to k folds.
%%%% ¡calculate!
d_list = nncv.get('D_LIST');
nn_list = nncv.get('NN_LIST');

if ~isa(nncv.getr('NNEVALUATOR_TEMPLATE'), 'NoValue')
    nne_template = nncv.get('NNEVALUATOR_TEMPLATE');
else¤
    nne_template = NNClassifierMLP_Evaluator( ...
        'P', nncv.get('P'));
¤end¤

value = cellfun(@(d, nn) NNClassifierMLP_Evaluator('TEMPLATE', nne_template, 'D', d, 'NN', nn), ...
    d_list, nn_list, 'UniformOutput', false);

\end{lstlisting}

\begin{lstlisting}[
	label={cd:m:NNClassifierMLP_CrossValidation:props},
	caption={
		{\bf NNClassifierMLP\_CrossValidation element props.}
		The \code{props} section of generator code for \fn{\_NNClassifierMLP\_CrossValidation.gen.m} defines the properties to be used in \fn{NNClassifierMLP\_CrossValidation}.
	}
]
¤%% ¡props!

%%% ¡prop!
P (parameter, scalar) is the permutation number.
%%%% ¡default!
1e+2
%%%% ¡check_prop!
check = value > 0 && value == round(value);¤

%%% ¡prop! ¥\circled{1}\circlednote{1}{ and \circled{2} calculate the average value of the area under the receiver operating characteristic curve across k folds.}¥
AV_AUC (result, rvector) provides the average value of the area under the receiver operating characteristic curve across k folds.
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

aucs = cellfun(@(e) e.get('AUC'), ...
    e_list, 'UniformOutput', false);

if isempty(aucs)
    value = [];
else
    value = mean(cell2mat(aucs), 1);
end

%%% ¡prop! ¥\circled{2}¥
AV_MACRO_AUC (result, scalar) provides the metric of the average macro AUC value across k folds.
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

macro_aucs = cellfun(@(e) e.get('MACRO_AUC'), ...
    e_list, 'UniformOutput', false);

if isempty(macro_aucs)
    value = 0;
else
    value = mean(cell2mat(macro_aucs), 1);
end

%%% ¡prop! ¥\circled{3}\circlednote{3}{ aggregates the confusion matrix across k folds.}¥
C_MATRIX (result, matrix) provides the confusion matrix across k folds.
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

c_matrices = cellfun(@(e) e.get('C_MATRIX'), ...
    e_list, 'UniformOutput', false);

combined_c_matrix = cellfun(@(x) double(x), c_matrices, 'UniformOutput', false);
value = sum(cat(3, combined_c_matrix{:}), 3);

¤%%% ¡prop!
AV_FEATURE_IMPORTANCE (result, cell) averages the feature importances across k folds.
%%%% ¡calculate!
e_list = nncv.get('EVALUATOR_LIST');

all_fi = cellfun(@(e) cell2mat(e.get('FEATURE_IMPORTANCE')), ...
    e_list, 'UniformOutput', false);

if isempty(cell2mat(all_fi))
    value = {};
else
    average_fi = zeros(size(all_fi{1}));
    for i = 1:numel(all_fi)
        % Add the current cell contents to the averageCell
        average_fi = average_fi + all_fi{i};
    end
    average_fi = average_fi / numel(all_fi);
    value = {average_fi};
end¤
\end{lstlisting}

\clearpage

\begin{lstlisting}[
	label=cd:m:NNClassifierMLP_CrossValidation:tests,
	caption={
		{\bf NNClassifierMLP\_CrossValidation element tests.}
		The \code{tests} section from the element generator \fn{\_NNClassifierMLP\_CrossValidation.gen.m}.
		A test for creating example files should be prepared to test the properties of the data point. Furthermore, additional test should be prepared for validating the value of input and target for the data point.
	}
]			
%% ¡tests!

%%% ¡test!
%%%% ¡name!
evaluate a classifier cross-validation with the example data
%%%% ¡code!

% ensure the example data is generated
if ~isfile([fileparts(which('NNDataPoint_CON_CLA')) filesep 'Example data NN CLA CON XLS' filesep 'atlas.xlsx'])
    test_NNDataPoint_CON_CLA % create example files
end

% Load BrainAtlas
im_ba = ImporterBrainAtlasXLS( ...
    'FILE', [fileparts(which('NNDataPoint_CON_CLA')) filesep 'Example data NN CLA CON XLS' filesep 'atlas.xlsx'], ...
    'WAITBAR', true ...
    );

ba = im_ba.get('BA');

% Load Groups of SubjectCON
im_gr1 = ImporterGroupSubjectCON_XLS( ...
    'DIRECTORY', [fileparts(which('NNDataPoint_CON_CLA')) filesep 'Example data NN CLA CON XLS' filesep 'CON_Group_1_XLS'], ...
    'BA', ba, ...
    'WAITBAR', true ...
    );

gr1 = im_gr1.get('GR');

im_gr2 = ImporterGroupSubjectCON_XLS( ...
    'DIRECTORY', [fileparts(which('NNDataPoint_CON_CLA')) filesep 'Example data NN CLA CON XLS' filesep 'CON_Group_2_XLS'], ...
    'BA', ba, ...
    'WAITBAR', true ...
    );

gr2 = im_gr2.get('GR');

% create item lists of NNDataPoint_CON_CLA
[~, group_folder_name] = fileparts(im_gr1.get('DIRECTORY'));
it_list1 = cellfun(@(x) NNDataPoint_CON_CLA( ...
    'ID', x.get('ID'), ...
    'SUB', x, ...
    'TARGET_IDS', {group_folder_name}), ...
    gr1.get('SUB_DICT').get('IT_LIST'), ...
    'UniformOutput', false);

[~, group_folder_name] = fileparts(im_gr2.get('DIRECTORY'));
it_list2 = cellfun(@(x) NNDataPoint_CON_CLA( ...
    'ID', x.get('ID'), ...
    'SUB', x, ...
    'TARGET_IDS', {group_folder_name}), ...
    gr2.get('SUB_DICT').get('IT_LIST'), ...
    'UniformOutput', false);

% create NNDataPoint_CON_CLA DICT items
dp_list1 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_CON_CLA', ...
        'IT_LIST', it_list1 ...
        );

dp_list2 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_CON_CLA', ...
        'IT_LIST', it_list2 ...
        );

% create a NNDataset containing the NNDataPoint_CON_CLA DICT
d1 = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_CON_CLA', ...
    'DP_DICT', dp_list1 ...
    );

d2 = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_CON_CLA', ...
    'DP_DICT', dp_list2 ...
    );

% combine the two datasets
d = NNDatasetCombine('D_LIST', {d1, d2}).get('D');

kfolds = 7;
nncv = NNClassifierMLP_CrossValidation('KFOLDS', kfolds, 'D', d);

nn_list = nncv.get('NN_LIST');
assert(length(nn_list) == kfolds, ... ¥\circled{1}\circlednote{1}{ and \circled{2} check whether the data, classifiers, and evaluators are initialized according to the user-specified number of folds.}¥
    [BRAPH2.STR ':NNClassifierMLP_CrossValidation:' BRAPH2.FAIL_TEST], ...
    'NNClassifierMLP_CrossValidation does not calculate the neural network list correctly.' ...
    )
e_list = nncv.get('EVALUATOR_LIST');
assert(length(e_list) == kfolds, ... ¥\circled{2}¥
    [BRAPH2.STR ':NNClassifierMLP_CrossValidation:' BRAPH2.FAIL_TEST], ...
    'NNClassifierMLP_CrossValidation does not calculate the evaluator list correctly.' ...
    )

\end{lstlisting}

%\bibliography{biblio}
%\bibliographystyle{plainnat}

\end{document}